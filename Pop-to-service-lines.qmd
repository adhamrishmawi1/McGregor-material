---
title: "Population-to-services_lines"
author: "Adham Rishmawi"
format: html
editor: visual
---

## Issue at hand

We are observing whether the population of a community is adding to the burden of the LSLRP by innately having more services lines in smaller communities than larger communities (10,000 plus)

## Setting

```{r, warning=FALSE,message=FALSE}
library(tidyverse)   
library(ggformula)
library(mosaic)
library(tidyr)
library(glmmTMB)
library(plotly)
library(forcats)
library(rworldmap)
```

## loading in the data

```{r}
data <- read.csv("~/Mcgregor Project/Data material/CSV-extracts from sql/population_to_service_lines.csv")
```

## explanatory graphs

```{r}
data_arranged <- data|> arrange(desc(data$Population))

ggplot(data_arranged, aes(x = reorder(Total_service_lines, -Population), y = Population)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "City", y = "Population", title = "City Population") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}

fig <- plot_ly(data = data_arranged, x = ~Total_service_lines, y = ~Population, type = "scatter", mode = 'markers', text = data_arranged$City, marker = list(opacity = 0.9))
fig <- fig|>layout(title = 'Population to lead city ratio in Michigan',
          xaxis = list(showgrid = FALSE),
         yaxis = list(showgrid = FALSE), showlegend = FALSE)


fig
```

## Converting the service lines to a ratio for population

```{r}
data$ratio_serv_pop <- data$Total_service_lines / data$Population
```

```{r}
fig1 <- plot_ly(data, x = ~Population, y = ~ratio_serv_pop, text = ~data$City, type = 'scatter', mode = 'markers')
fig1
```

```{r}
fig1 <- plot_ly(data, x = ~Population, y = ~ratio_serv_pop, text = ~data$City, type = 'scatter', mode = 'markers')
fig1 <- fig1 %>% layout(xaxis = list(range = c(0, 70000)), yaxis = list(range = c(0, 2)))
fig1


```

## Chi square test/Pearson Correlation test

```{r}
poptable <- data$Population
servtable <- data$Total_service_lines

result <- cor.test(poptable,servtable)

print(result)
```

The output you provided is the result of a Pearson's product-moment correlation test. Let's break down the information:

1.  **data**: This line indicates that the test was performed on variables "x" and "y".

2.  **t-value**: The t-value is a measure of the strength and direction of the correlation. In this case, the t-value is 62.001.

3.  **df**: df represents the degrees of freedom, which is a measure of the amount of information available for the test. In this case, there are 287 degrees of freedom.

4.  **p-value**: The p-value is a measure of the statistical significance of the correlation. It indicates the probability of observing a correlation as extreme as the one obtained in the sample, assuming the null hypothesis is true. A p-value less than 0.05 (commonly used significance level) suggests strong evidence against the null hypothesis. In this case, the p-value is reported as less than 2.2e-16, which is essentially 0, indicating a highly significant result.

5.  **alternative hypothesis**: The alternative hypothesis states that the true correlation is not equal to 0. In other words, it suggests that there is a significant correlation between variables "x" and "y".

6.  **confidence interval**: The 95 percent confidence interval provides a range of values within which we can be 95% confident that the true correlation lies. In this case, the confidence interval is reported as 0.9556190 to 0.9718514.

7.  **sample estimate**: The sample estimate is the point estimate of the correlation coefficient. In this case, the estimated correlation coefficient (cor) is 0.9646386, indicating a strong positive correlation between "x" and "y".

In summary, the results indicate a highly significant and strong positive correlation (0.9646) between variables "x" and "y", suggesting that as "x" increases, "y" tends to increase as well. The correlation is statistically significant at a 95% confidence level, based on the low p-value (\< 2.2e-16) and the confidence interval (0.9556 to 0.9719).
